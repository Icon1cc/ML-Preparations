# Embeddings for RAG

Embeddings are the backbone of the Retrieval-Augmented Generation (RAG) architecture. They translate human-readable text into a machine-readable mathematical format where "semantic distance" equates to "mathematical distance."

---

## What is an Embedding?
An embedding is a dense vector (an array of floating-point numbers) that represents the semantic meaning of a piece of text (a word, sentence, or document).
*   **Example:** The sentence "The cat sat on the mat" might be translated into `[0.12, -0.45, 0.89, ...]` across 768 dimensions.
*   **Property:** In a good embedding space, the vector for "dog" will be geometrically closer to "cat" than it is to "car".

## How are Embeddings Generated?
Embeddings are generated by specialized neural networks (not generative LLMs). These models are typically Encoder-only Transformers (like BERT).
1.  **Input:** Text chunk.
2.  **Process:** The text is tokenized and passed through the Encoder layers. The model uses self-attention to understand the context of each word relative to the others.
3.  **Output:** The final hidden state (often the `[CLS]` token's vector, or a mean-pooling of all token vectors) is extracted as the single embedding vector for the entire chunk.

## Key Concepts & Metrics

### 1. Dimensionality
The length of the embedding vector (e.g., 384, 768, 1536).
*   **Trade-off:** Higher dimensions capture more nuanced semantic meaning but require much more RAM/storage in the Vector DB and are slower to search.
*   **Trend:** Modern models like OpenAI's `text-embedding-3-large` use "Matryoshka Representation Learning," which allows developers to truncate the embedding (e.g., from 3072 down to 256 dimensions) without drastically losing performance, saving massive storage costs.

### 2. Distance Metrics
How do we mathematically determine if two vectors are similar?
*   **Cosine Similarity (Most Common):** Measures the *angle* between two vectors, regardless of their magnitude (length). Ranges from -1 (opposite) to 1 (identical). Formula: `(A Â· B) / (||A|| * ||B||)`
*   **Dot Product:** If the embedding vectors are normalized (magnitude of 1), Dot Product is mathematically identical to Cosine Similarity, but much faster to compute. This is the standard for production vector DBs.
*   **Euclidean Distance (L2):** Measures the straight-line distance between the endpoints of two vectors. Used less often for text embeddings unless vectors are normalized.

### 3. Asymmetric vs. Symmetric Search
*   **Symmetric Search:** The query and the documents are of similar length and type (e.g., finding similar news articles based on another news article).
*   **Asymmetric Search (RAG Default):** The query is short (a question) and the documents are long (paragraphs containing the answer). You need an embedding model specifically trained for asymmetric search (often denoted by models expecting "query:" or "passage:" prefixes).

## Choosing an Embedding Model (Interview Tips)
Don't just default to OpenAI in an interview. Discuss tradeoffs:

| Model Category | Examples | Pros | Cons |
| :--- | :--- | :--- | :--- |
| **Commercial API** | OpenAI `text-embedding-3-small`, Cohere | Extremely easy to use, high quality, zero infrastructure. | Cost at scale, latency (network call), data privacy (sending data outside your VPC). |
| **Open Source (Self-Hosted)** | BAAI `bge-large-en`, `e5-mistral` | Free, private (runs in your VPC), customizable. | Requires you to manage infrastructure (GPUs/CPUs for inference). |
| **Specialized/Domain** | `ClinicalBERT` | Unbeatable for highly technical jargon (medical, legal). | Very poor at general domain questions. |

**Best Practice:** Always check the **MTEB (Massive Text Embedding Benchmark)** leaderboard on HuggingFace to see current state-of-the-art models for specific tasks (retrieval vs. classification).